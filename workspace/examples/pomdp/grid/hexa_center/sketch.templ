// 4x4 grid
// from Littman, Cassandra and Kaelbling
// Learning policies for partially observable environments: Scaling up  
// Technical Report CS, Brown University

pomdp


// only the target is observable which is in the south east corner
observables
	o
endobservables

const double sl=0.2;


// new coordinates
formula yn  = min(y+1,3);
formula ys  = max(y-1,0);
formula xe  = min(x+1,3);
formula xw  = max(x-1,0);



module grid
	
	x : [0..3]; // x coordinate
	y : [0..3]; // y coordinate
	o : [0..3]; // observables

	// 0 - initial observation
	// 1 - in the grid (not target)
	// 2 - observe target
	// 3 - bad state
		
	// initially randomly placed within the grid (not at the target)
	[] o=0 -> 1/14 : (o'=1) & (x'=0) & (y'=0)
			+ 1/14 : (o'=1) & (x'=0) & (y'=1)
			+ 1/14 : (o'=1) & (x'=0) & (y'=2)
			+ 1/14 : (o'=1) & (x'=0) & (y'=3)
			+ 1/14 : (o'=1) & (x'=1) & (y'=0)
			//+ 1/15 : (o'=1) & (x'=1) & (y'=1)
			+ 1/14 : (o'=1) & (x'=1) & (y'=2)
			+ 1/14 : (o'=1) & (x'=1) & (y'=3)	
			+ 1/14 : (o'=1) & (x'=2) & (y'=0)
			+ 1/14 : (o'=1) & (x'=2) & (y'=1)
			// + 1/14 : (o'=1) & (x'=2) & (y'=2) // this is the traget
			+ 1/14 : (o'=1) & (x'=2) & (y'=3)	
			+ 1/14 : (o'=1) & (x'=3) & (y'=0) 
			+ 1/14 : (o'=1) & (x'=3) & (y'=1)
			+ 1/14 : (o'=1) & (x'=3) & (y'=2)
			+ 1/14 : (o'=1) & (x'=3) & (y'=3);
			
	// move around the grid

	[north] o=1 & !(x=2 & y=1) & !(x=1 & y=0) -> (1-sl): (y'=yn) + sl: true; 
	[north] o=1 & (x=2 & y=1) -> (1-sl): (y'=yn) & (o'=2) + sl: true; // T
	[north] o=1 & (x=1 & y=0) -> (1-sl): (y'=yn) & (o'=3) + sl: true; // B

	[north_east] o=1 & !(x=1 & y=2) & !(x=0 & y=1) -> (1-sl):  (x'=xe) + sl: true;
	[north_east] o=1 & (x=1 & y=2) -> (1-sl): (x'=xe) & (o'=2) + sl: true; // T
	[north_east] o=1 & (x=0 & y=1) -> (1-sl): (x'=xe) & (o'=3) + sl: true; // B

	[south_east] o=1 & !(x=1 & y=3) & !(x=0 & y=2) -> (1-sl): (y'=ys) & (x'=xe) + sl: true;
	[south_east] o=1 & (x=1 & y=3) -> (1-sl): (y'=ys) & (x'=xe) & (o'=2) + sl: true; // T
	[south_east] o=1 & (x=0 & y=2) -> (1-sl): (y'=ys) & (x'=xe) & (o'=3) + sl: true; // B
	
	[south] o=1 & !(x=2 & y=3) & !(x=1 & y=2) -> (1-sl): (y'=ys) + sl: true;
	[south] o=1 & (x=2 & y=3) -> (1-sl): (y'=ys) & (o'=2) + sl: true; // T
	[south] o=1 & (x=1 & y=2) -> (1-sl): (y'=ys) & (o'=3) + sl: true; // B

	[south_west] o=1 & !(x=3 & y=2) & !(x=2 & y=1) -> (1-sl): (x'=xw) + sl: true;
	[south_west] o=1 & (x=3 & y=2) -> (1-sl): (x'=xw) & (o'=2) + sl: true; // T
	[south_west] o=1 & (x=2 & y=1) -> (1-sl): (x'=xw) & (o'=3) + sl: true; // B

	[north_west] o=1 & !(x=3 & y=1) & !(x=2 & y=1) -> (1-sl): (y'=yn) & (x'=xw) + sl: true;
	[north_west] o=1 & (x=3 & y=1) -> (1-sl): (y'=yn) & (x'=xw) & (o'=2) + sl: true; // T
	[north_west] o=1 & (x=2 & y=1) -> (1-sl): (y'=yn) & (x'=xw) & (o'=3) + sl: true; // B

	
	// reached target
	[done] o=2 -> true;
	
	//reached bad state
	//[bad] o=3 -> true;
	
endmodule

// reward structure for number of steps to reach the target
rewards "steps"
		[north]			true : 1;
        [north_east]	true : 1;
        [south_east]	true : 1;
        [south]			true : 1;
		[south_west]	true : 1;
		[north_west]	true : 1;
endrewards

// target observation
label "goal" = o=2;
label "bad"  = o=3;